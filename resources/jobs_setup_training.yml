# Setup and Training Jobs - Phase 1 Deployment
# Deploy these first to create catalog and train model

resources:
  jobs:
    # Setup job - Create Unity Catalog tables and schemas
    setup_unity_catalog:
      name: "[${bundle.target}] Entity Matching - Setup Unity Catalog"

      tasks:
        - task_key: create_catalog_and_schemas
          notebook_task:
            notebook_path: ../notebooks/setup/01_create_unity_catalog.py
            base_parameters:
              catalog_name: ${var.catalog_name}
          new_cluster:
            node_type_id: ${var.cluster_node_type}
            spark_version: ${var.cluster_spark_version}
            num_workers: 1
            spark_conf:
              spark.databricks.delta.preview.enabled: "true"
          timeout_seconds: 1800

        - task_key: create_reference_tables
          depends_on:
            - task_key: create_catalog_and_schemas
          notebook_task:
            notebook_path: ../notebooks/setup/02_create_reference_tables.py
            base_parameters:
              catalog_name: ${var.catalog_name}
          new_cluster:
            node_type_id: ${var.cluster_node_type}
            spark_version: ${var.cluster_spark_version}
            num_workers: 2
          timeout_seconds: 3600

      max_concurrent_runs: 1
      tags:
        project: entity_matching
        environment: ${bundle.target}

    # Training job - Generate training data and train Ditto model
    train_ditto_model:
      name: "[${bundle.target}] Entity Matching - Train Ditto Model"

      tasks:
        - task_key: generate_training_data
          notebook_task:
            notebook_path: ../notebooks/02_train_ditto_model.py
            base_parameters:
              catalog_name: ${var.catalog_name}
              num_positive_pairs: "1000"
              num_negative_pairs: "1000"
              output_path: ${workspace.root_path}/training_data
          new_cluster:
            node_type_id: ${var.cluster_node_type}
            spark_version: ${var.cluster_spark_version}
            num_workers: 4
            spark_conf:
              spark.databricks.delta.preview.enabled: "true"
          libraries:
            - pypi:
                package: sentence-transformers==2.2.2
            - pypi:
                package: torch==2.1.0
          timeout_seconds: 7200

        - task_key: train_model
          depends_on:
            - task_key: generate_training_data
          python_wheel_task:
            package_name: entity_matching
            entry_point: train_ditto
            parameters:
              - --training-data
              - ${workspace.root_path}/training_data/ditto_training.csv
              - --output-path
              - ${workspace.root_path}/models/ditto_matcher
              - --epochs
              - "20"
          new_cluster:
            node_type_id: i3.xlarge
            spark_version: ${var.cluster_spark_version}
            num_workers: 0 # Single node for training
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode
          libraries:
            - pypi:
                package: torch==2.1.0
            - pypi:
                package: transformers==4.36.0
            - pypi:
                package: sentence-transformers==2.2.2
          timeout_seconds: 14400 # 4 hours

        - task_key: register_model
          depends_on:
            - task_key: train_model
          notebook_task:
            notebook_path: ../notebooks/setup/03_register_model.py
            base_parameters:
              model_path: ${workspace.root_path}/models/ditto_matcher
              model_name: ${var.catalog_name}.models.entity_matching_ditto
          new_cluster:
            node_type_id: ${var.cluster_node_type}
            spark_version: ${var.cluster_spark_version}
            num_workers: 1
          timeout_seconds: 1800

      max_concurrent_runs: 1
      email_notifications:
        on_success:
          - ${workspace.current_user.userName}@databricks.com
        on_failure:
          - ${workspace.current_user.userName}@databricks.com
      tags:
        project: entity_matching
        environment: ${bundle.target}
        type: training
